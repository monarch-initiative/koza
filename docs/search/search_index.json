{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Koza","text":""},{"location":"#a-data-transformation-framework-in-python","title":"A data transformation framework in Python","text":""},{"location":"#overview","title":"Overview","text":"<p>Koza is a data transformation framework which allows you to write semi-declarative \"ingests\"</p> <ul> <li>Transform csv, json, yaml, jsonl, or xml source data, converting them to a target csv, json, or jsonl format based on your dataclass model.  </li> <li>Koza also can output data in the KGX format</li> <li>Write data transforms in semi-declarative Python</li> <li>Configure source files, expected columns/json properties and path filters, field filters, and metadata in yaml</li> <li>Create or import mapping files to be used in ingests (eg. id mapping, type mappings)</li> <li>Create and use translation tables to map between source and target vocabularies</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Koza is available on PyPi and can be installed via pip: <pre><code>pip install koza\n</code></pre></p>"},{"location":"#usage","title":"Usage","text":"<p>See the Ingests page for information on how to configure ingests for koza to use.</p> <p>Koza can be used as a Python library, or via the command line. CLI commands are available for validating and transforming data. See the Module page for information on using Koza as a library.</p> <p>Koza also includes some examples to help you get started (see <code>koza/examples</code>).</p>"},{"location":"#basic-examples","title":"Basic Examples","text":"<p>Validate</p> <p>Give Koza a local or remote csv file, and get some basic information (headers, number of rows)</p> <pre><code>koza validate \\\n  --file ./examples/data/string.tsv \\\n  --delimiter ' '\n</code></pre> <p>Sending a json or jsonl formatted file will confirm if the file is valid json or jsonl</p> <pre><code>koza validate \\\n  --file ./examples/data/ZFIN_PHENOTYPE_0.jsonl.gz \\\n  --format jsonl\n</code></pre> <pre><code>koza validate \\\n  --file ./examples/data/ddpheno.json.gz \\\n  --format json\n</code></pre> <p>Transform</p> <p>Try one of Koza's example ingests: <pre><code>koza transform \\\n  --source examples/string-declarative/protein-links-detailed.yaml \\\n  --global-table examples/translation_table.yaml\n</code></pre></p> <p>Note:    Koza expects a directory structure as described in the above example   with the source config file and transform code in the same directory   (these files can also simply be named <code>transform.yaml</code> and <code>transform.py</code>, as is default):    <pre><code>.\n\u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 some_source\n\u2502   \u2502   \u251c\u2500\u2500 your_ingest.yaml\n\u2502   \u2502   \u2514\u2500\u2500 your_ingest.py\n\u2502   \u2514\u2500\u2500 some_translation_table.yaml\n\u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"Ingests/","title":"Configuring an Ingest","text":"<p><sub> (For CLI usage, see the CLI commands page.) </sub> </p> <p>Koza is designed to process and transform existing data into a target csv/json/jsonl format.  </p> <p>This process is internally known as an ingest. Ingests are defined by:  </p> <ol> <li>Source config yaml: Ingest configuration, including:<ul> <li>metadata, formats, required columns, any SSSOM files, etc. </li> </ul> </li> <li>Map config yaml: (Optional) configures creation of mapping dictionary  </li> <li>Transform code: a Python script, with specific transform instructions </li> </ol>"},{"location":"Ingests/mapping/","title":"Mapping","text":"<p>Mapping with Koza is optional, but can be done in two ways:  </p> <ul> <li>Automated mapping with SSSOM files  </li> <li>Manual mapping with a map config yaml</li> </ul>"},{"location":"Ingests/mapping/#sssom-mapping","title":"SSSOM Mapping","text":"<p>Koza supports mapping with SSSOM files (Semantic Similarity of Source and Target Ontology Mappings). Simply add the path to the SSSOM file to your source config, the desired target prefixes, and any prefixes you want to use to filter the SSSOM file. Koza will automatically create a mapping lookup table which will automatically attempt to map any values in the source file to an ID with the target prefix.</p> <pre><code>sssom_config:\n    sssom_file: './path/to/your_mapping_file.sssom.tsv'\n    filter_prefixes: \n        - 'SOMEPREFIX'\n        - 'OTHERPREFIX'\n    target_prefixes: \n        - 'OTHERPREFIX'\n    use_match:\n        - 'exact'\n</code></pre> <p>Note: Currently, only the <code>exact</code> match type is supported (<code>narrow</code> and <code>broad</code> match types will be added in the future).</p>"},{"location":"Ingests/mapping/#manual-mapping-additional-data","title":"Manual Mapping / Additional Data","text":"<p>The map config yaml allows you to include data from other sources in your ingests, which may have different columns or formats.  </p> <p>If you don't have an SSSOM file, or you want to manually map some values, you can use a map config yaml. You can then add this map to your source config yaml in the <code>depends_on</code> property.  </p> <p>Koza will then create a nested dictionary with the specified key and values. For example, the following map config yaml maps values from the <code>STRING</code> column to the <code>entrez</code> and <code>NCBI taxid</code> columns.</p> <pre><code># koza/examples/maps/entrez-2-string.yaml\nname: ...\nfiles: ...\n\ncolumns:\n- 'NCBI taxid'\n- 'entrez'\n- 'STRING'\n\nkey: 'STRING'\n\nvalues:\n- 'entrez'\n- 'NCBI taxid'\n</code></pre> <p>The mapping dict will be available in your transform script from the <code>koza_app</code> object (see the Transform Code section below).</p> <p>Next Steps: Transform Code</p>"},{"location":"Ingests/source_config/","title":"Source Config","text":"<p>This YAML file sets properties for the ingest of a single file type from a within a Source.</p> <p>Paths are relative to the directory from which you execute Koza.</p>"},{"location":"Ingests/source_config/#source-configuration-properties","title":"Source Configuration Properties","text":"Required properties <code>name</code> Name of the data ingest, as <code>&lt;data source&gt;_&lt;type_of_ingest&gt;</code>, ex. <code>hpoa_gene_to_disease</code> <code>files</code> List of files to process <code>node_properties</code> List of node properties to include in output <code>edge_properties</code> List of edge properties to include in output Note Either node or edge properties (or both) must be defined in the primary config yaml for your transform Optional properties <code>file_archive</code> Path to a file archive containing the file(s) to process  Supported archive formats: zip, gzip <code>format</code> Format of the data file(s) (CSV or JSON) <code>sssom_config</code> Configures usage of SSSOM mapping files <code>depends_on</code> List of map config files to use <code>metadata</code> Metadata for the source, either a list of properties,or path to a <code>metadata.yaml</code> <code>transform_code</code> Path to a python file to transform the data <code>transform_mode</code> How to process the transform file <code>global_table</code> Path to a global translation table file <code>local_table</code> Path to a local translation table file <code>field_type_map</code> Dict of field names and their type (using the FieldType enum) <code>filters</code> List of filters to apply <code>json_path</code> Path within JSON object containing data to process <code>required_properties</code> List of properties that must be present in output (JSON only) CSV-Specific Properties <code>delimiter</code> Delimiter for csv files (Required for CSV format) Optional CSV Properties <code>columns</code> List of columns to include in output (CSV only) <code>header</code> Header row index for csv files <code>header_delimiter</code> Delimiter for header in csv files <code>header_prefix</code> Prefix for header in csv files <code>comment_char</code> Comment character for csv files <code>skip_blank_lines</code> Skip blank lines in csv files"},{"location":"Ingests/source_config/#metadata-properties","title":"Metadata Properties","text":"<p>Metadata is optional, and can be defined as a list of properties and values, or as a path to a <code>metadata.yaml</code> file, for example - <code>metadata: \"./path/to/metadata.yaml\"</code>. Remember that the path is relative to the directory from which you execute Koza.</p> Metadata Properties name Name of data source, ex. \"FlyBase\" description Description of data/ingest ingest_title *Title of source of data, map to biolink name ingest_url *URL to source of data, Maps to biolink iri provided_by <code>&lt;data source&gt;_&lt;type_of_ingest&gt;</code>, ex. <code>hpoa_gene_to_disease</code> (see config propery \"name\") rights Link to license information for the data source <p>*Note: For more information on <code>ingest_title</code> and <code>ingest_url</code>, see the infores catalog</p>"},{"location":"Ingests/source_config/#composing-configuration-from-multiple-yaml-files","title":"Composing Configuration from Multiple Yaml Files","text":"<p>Koza's custom YAML Loader supports importing/including other yaml files with an <code>!include</code> tag.</p> <p>For example, if you had a file named <code>standard-columns.yaml</code>:</p> <pre><code>- \"column_1\"\n- \"column_2\"\n- \"column_3\"\n- \"column_4\": \"int\"\n</code></pre> <p>Then in any ingests you wish to use these columns, you can simply <code>!include</code> them:</p> <pre><code>columns: !include \"./path/to/standard-columns.yaml\"\n</code></pre> <p>Next Steps: Mapping and Additional Data</p>"},{"location":"Ingests/testing/","title":"Testing","text":"<p>Koza includes a <code>mock_koza</code> fixture (see <code>src/koza/utils/testing_utils</code>) that can be used to test your ingest configuration. This fixture accepts the following arguments:</p> Argument Type Description Required Arguments <code>name</code> <code>str</code> The name of the ingest <code>data</code> <code>Union[Dict, List[Dict]]</code> The data to be ingested <code>transform_code</code> <code>str</code> Path to the transform code to be used Optional Arguments <code>map_cache</code> <code>Dict</code> Map cache to be used <code>filters</code> <code>List(str)</code> List of filters to apply to data <code>global_table</code> <code>str</code> Path to the global table <code>local_table</code> <code>str</code> Path to the local table <p>The <code>mock_koza</code> fixture returns a list of entities that would be generated by the ingest configuration. This list can then be used to test the output based on the transform script.</p> <p>Here is an example of how to use the <code>mock_koza</code> fixture to test an ingest configuration:</p> <pre><code>import pytest\n\nfrom koza.utils.testing_utils import mock_koza\n\n# Define the source name and transform script path\nINGEST_NAME = \"your_ingest_name\"\nTRANSFORM_SCRIPT = \"./src/{{cookiecutter.__project_slug}}/transform.py\"\n\n# Define an example row to test (as a dictionary)\n@pytest.fixture\ndef example_row():\n    return {\n        \"example_column_1\": \"entity_1\",\n        \"example_column_2\": \"entity_6\",\n        \"example_column_3\": \"biolink:related_to\",\n    }\n\n# Or a list of rows\n@pytest.fixture\ndef example_list_of_rows():\n    return [\n        {\n            \"example_column_1\": \"entity_1\",\n            \"example_column_2\": \"entity_6\",\n            \"example_column_3\": \"biolink:related_to\",\n        },\n        {\n            \"example_column_1\": \"entity_2\",\n            \"example_column_2\": \"entity_7\",\n            \"example_column_3\": \"biolink:related_to\",\n        },\n    ]\n\n# Define the mock koza transform\n@pytest.fixture\ndef mock_transform(mock_koza, example_row):\n    return mock_koza(\n        INGEST_NAME,\n        example_row,\n        TRANSFORM_SCRIPT,\n    )\n\n# Or for multiple rows\n@pytest.fixture\ndef mock_transform_multiple_rows(mock_koza, example_list_of_rows):\n    return mock_koza(\n        INGEST_NAME,\n        example_list_of_rows,\n        TRANSFORM_SCRIPT,\n    )\n\n# Test the output of the transform\n\ndef test_single_row(mock_transform):\n    assert len(mock_transform) == 1\n    entity = mock_transform[0]\n    assert entity\n    assert entity.subject == \"entity_1\"\n\n\ndef test_multiple_rows(mock_transform_multiple_rows):\n    assert len(mock_transform_multiple_rows) == 2\n    entity_1 = mock_transform_multiple_rows[0]\n    entity_2 = mock_transform_multiple_rows[1]\n    assert entity_1.subject == \"entity_1\"\n    assert entity_2.subject == \"entity_2\"\n</code></pre>"},{"location":"Ingests/transform/","title":"Transform Code","text":"<p>This Python script is where you'll define the specific steps of your data transformation. Koza will load this script and execute it for each row of data in your source file, applying any filters and mapping as defined in your source config yaml, and outputting the transformed data to the target csv/json/jsonl file.</p> <p>When Koza is called, either by command-line or as a library using <code>transform_source()</code>, it creates a <code>KozaApp</code> object for the specified ingest. This KozaApp will be your entry point to Koza:</p> <pre><code>from koza.cli_utils import get_koza_app\nkoza_app = get_koza_app('your-source-name')\n</code></pre> <p>The KozaApp object has the following methods which can be used in your transform code:</p> Method Description <code>get_row()</code> Returns the next row of data from the source file <code>next_row()</code> Skip to the next row in the data file <code>get_map(map_name)</code> Returns the mapping dict for the specified map <code>process_sources()</code> TBD <code>process_maps()</code> Initializes the KozaApp's map cache <code>write(*args)</code> Writes the transformed data to the target file <p>Once you have processed a row of data, and created a biolink entity node or edge object (or both), you can pass these to <code>koza_app.write()</code> to output the transformed data to the target file.</p> Example Python Transform Script <pre><code># other imports, eg. uuid, pydantic, etc.\nimport uuid\nfrom biolink_model.datamodel.pydanticmodel_v2 import Gene, PairwiseGeneToGeneInteraction\n\n# Koza imports\nfrom koza.cli_utils import get_koza_app\n\n# This is the name of the ingest you want to run\nsource_name = 'map-protein-links-detailed'\nkoza_app = get_koza_app(source_name)\n\n# If your ingest depends_on a mapping file, you can access it like this:\nmap_name = 'entrez-2-string'\nkoza_map = koza_app.get_map(map_name)\n\n# This grabs the first/next row from the source data\n# Koza will reload this script and return the next row until it reaches EOF or row-limit\nwhile (row := koza_app.get_row()) is not None:\n    # Now you can lay out your actual transformations, and define your output:\n\n    gene_a = Gene(id='NCBIGene:' + koza_map[row['protein1']]['entrez'])\n    gene_b = Gene(id='NCBIGene:' + koza_map[row['protein2']]['entrez'])\n\n    pairwise_gene_to_gene_interaction = PairwiseGeneToGeneInteraction(\n        id=\"uuid:\" + str(uuid.uuid1()),\n        subject=gene_a.id,\n        object=gene_b.id,\n        predicate=\"biolink:interacts_with\"\n    )\n\n    # Finally, write the transformed row to the target file\n    koza_app.write(gene_a, gene_b, pairwise_gene_to_gene_interaction)\n</code></pre> <p>If you pass nodes, as well as edges, to <code>koza_app.write()</code>, Koza will automatically create a node file and an edge file. If you pass only nodes, Koza will create only a node file, and if you pass only edges, Koza will create only an edge file.</p>"},{"location":"Usage/CLI/","title":"<code>koza</code>","text":"<p>Usage:</p> <pre><code>$ koza [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--version</code></li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>transform</code>: Transform a source file</li> <li><code>validate</code>: Validate a source file</li> </ul>"},{"location":"Usage/CLI/#koza-transform","title":"<code>koza transform</code>","text":"<p>Transform a source file</p> <p>Usage:</p> <pre><code>$ koza transform [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--source TEXT</code>: Source metadata file  [required]</li> <li><code>--output-dir TEXT</code>: Path to output directory  [default: ./output]</li> <li><code>--output-format [tsv|jsonl|kgx]</code>: Output format  [default: tsv]</li> <li><code>--global-table TEXT</code>: Path to global translation table</li> <li><code>--local-table TEXT</code>: Path to local translation table</li> <li><code>--schema TEXT</code>: Path to schema YAML for validation in writer</li> <li><code>--row-limit INTEGER</code>: Number of rows to process (if skipped, processes entire source file)</li> <li><code>--debug / --quiet</code></li> <li><code>--log / --no-log</code>: Optional log mode - set true to save output to ./logs  [default: no-log]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"Usage/CLI/#koza-validate","title":"<code>koza validate</code>","text":"<p>Validate a source file</p> <p>Usage:</p> <pre><code>$ koza validate [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--file TEXT</code>: Path or url to the source file  [required]</li> <li><code>--format [csv|jsonl|json|yaml]</code>: [default: csv]</li> <li><code>--delimiter TEXT</code>: [default: ,]</li> <li><code>--header-delimiter TEXT</code></li> <li><code>--skip-blank-lines / --no-skip-blank-lines</code>: [default: skip-blank-lines]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"Usage/Module/","title":"Module","text":"<p>Module for managing koza runs through the CLI</p>"},{"location":"Usage/Module/#src.koza.cli_utils.get_koza_app","title":"<code>get_koza_app</code>","text":"<p>Return a KozaApp object for a given source</p> <p>Parameters:</p> Name Type Description Default <code>source_name</code> <code>str</code> <p>Name of source</p> required Source code in <code>src/koza/cli_utils.py</code> <pre><code>def get_koza_app(source_name) -&gt; Optional[KozaApp]:\n    \"\"\"Return a KozaApp object for a given source\n\n    Args:\n        source_name (str): Name of source\n    \"\"\"\n    try:\n        return koza_apps[source_name]\n    except KeyError:\n        raise KeyError(f\"{source_name} was not found in KozaApp dictionary\")\n</code></pre>"},{"location":"Usage/Module/#src.koza.cli_utils.get_translation_table","title":"<code>get_translation_table</code>","text":"<p>Create a translation table object from two file paths</p> <p>Parameters:</p> Name Type Description Default <code>global_table</code> <code>str</code> <p>Path to global translation table. Defaults to None.</p> <code>None</code> <code>local_table</code> <code>str</code> <p>Path to local translation table. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TranslationTable</code> <code>TranslationTable</code> <p>TranslationTable object</p> Source code in <code>src/koza/cli_utils.py</code> <pre><code>def get_translation_table(\n    global_table: Union[str, Dict] = None,\n    local_table: Union[str, Dict] = None,\n    logger=None,\n) -&gt; TranslationTable:\n    \"\"\"Create a translation table object from two file paths\n\n    Args:\n        global_table (str, optional): Path to global translation table. Defaults to None.\n        local_table (str, optional): Path to local translation table. Defaults to None.\n\n    Returns:\n        TranslationTable: TranslationTable object\n    \"\"\"\n\n    global_tt = {}\n    local_tt = {}\n\n    if not global_table:\n        if local_table:\n            raise ValueError(\"Local table without a global table not allowed\")\n        else:\n            logger.debug(\"No global table used for transform\")\n    else:\n        if isinstance(global_table, str):\n            with open(global_table, \"r\") as global_tt_fh:\n                global_tt = yaml.safe_load(global_tt_fh)\n        elif isinstance(global_table, Dict):\n            global_tt = global_table\n\n        if local_table:\n            if isinstance(local_table, str):\n                with open(local_table, \"r\") as local_tt_fh:\n                    local_tt = yaml.safe_load(local_tt_fh)\n            elif isinstance(local_table, Dict):\n                local_tt = local_table\n\n        else:\n            logger.debug(\"No local table used for transform\")\n\n    return TranslationTable(global_tt, local_tt)\n</code></pre>"},{"location":"Usage/Module/#src.koza.cli_utils.transform_source","title":"<code>transform_source</code>","text":"<p>Create a KozaApp object, process maps, and run the transform</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Path to source metadata file</p> required <code>output_dir</code> <code>str</code> <p>Path to output directory</p> required <code>output_format</code> <code>OutputFormat</code> <p>Output format. Defaults to OutputFormat('tsv').</p> <code>OutputFormat('tsv')</code> <code>global_table</code> <code>str</code> <p>Path to global translation table. Defaults to None.</p> <code>None</code> <code>local_table</code> <code>str</code> <p>Path to local translation table. Defaults to None.</p> <code>None</code> <code>schema</code> <code>str</code> <p>Path to schema file. Defaults to None.</p> <code>None</code> <code>row_limit</code> <code>int</code> <p>Number of rows to process. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Verbose logging. Defaults to None.</p> <code>None</code> <code>log</code> <code>bool</code> <p>Log to file. Defaults to False.</p> <code>False</code> Source code in <code>src/koza/cli_utils.py</code> <pre><code>def transform_source(\n    source: str,\n    output_dir: str,\n    output_format: OutputFormat = OutputFormat(\"tsv\"),\n    global_table: str = None,\n    local_table: str = None,\n    schema: str = None,\n    node_type: str = None,\n    edge_type: str = None,\n    row_limit: int = None,\n    verbose: bool = None,\n    log: bool = False,\n):\n    \"\"\"Create a KozaApp object, process maps, and run the transform\n\n    Args:\n        source (str): Path to source metadata file\n        output_dir (str): Path to output directory\n        output_format (OutputFormat, optional): Output format. Defaults to OutputFormat('tsv').\n        global_table (str, optional): Path to global translation table. Defaults to None.\n        local_table (str, optional): Path to local translation table. Defaults to None.\n        schema (str, optional): Path to schema file. Defaults to None.\n        row_limit (int, optional): Number of rows to process. Defaults to None.\n        verbose (bool, optional): Verbose logging. Defaults to None.\n        log (bool, optional): Log to file. Defaults to False.\n    \"\"\"\n    logger = get_logger(name=Path(source).name if log else None, verbose=verbose)\n\n    with open(source, \"r\") as source_fh:\n        source_config = PrimaryFileConfig(**yaml.load(source_fh, Loader=UniqueIncludeLoader))\n\n    # Set name and transform code if not provided\n    if not source_config.name:\n        source_config.name = Path(source).stem\n\n    if not source_config.transform_code:\n        filename = f\"{Path(source).parent / Path(source).stem}.py\"\n        if not Path(filename).exists():\n            filename = Path(source).parent / \"transform.py\"\n        if not Path(filename).exists():\n            raise FileNotFoundError(f\"Could not find transform file for {source}\")\n        source_config.transform_code = filename\n\n    koza_source = Source(source_config, row_limit)\n    logger.debug(f\"Source created: {koza_source.config.name}\")\n    translation_table = get_translation_table(\n        global_table if global_table else source_config.global_table,\n        local_table if local_table else source_config.local_table,\n        logger,\n    )\n\n    koza_app = _set_koza_app(\n        koza_source, translation_table, output_dir, output_format, schema, node_type, edge_type, logger\n    )\n    koza_app.process_maps()\n    koza_app.process_sources()\n\n    ### QC checks\n\n    def _check_row_count(type: Literal[\"node\", \"edge\"]):\n        \"\"\"Check row count for nodes or edges.\"\"\"\n\n        if type == \"node\":\n            outfile = koza_app.node_file\n            min_count = source_config.min_node_count\n        elif type == \"edge\":\n            outfile = koza_app.edge_file\n            min_count = source_config.min_edge_count\n\n        count = duckdb.sql(f\"SELECT count(*) from '{outfile}' as count\").fetchone()[0]\n\n        if row_limit and row_limit &lt; min_count:\n            logger.warning(f\"Row limit '{row_limit}' is less than expected count of {min_count} {type}s\")\n        elif row_limit and row_limit &lt; count:\n            logger.error(f\"Actual {type} count {count} exceeds row limit {row_limit}\")\n        else:\n            if count &lt; min_count * 0.7:\n                raise ValueError(f\"Actual {type} count {count} is less than 70% of expected {min_count} {type}s\")\n            if min_count * 0.7 &lt;= count &lt; min_count:\n                logger.warning(\n                    f\"Actual {type} count {count} is less than expected {min_count}, but more than 70% of expected\"\n                )\n\n    # Confirm min number of rows in output\n    if hasattr(koza_app, \"node_file\") and source_config.min_node_count is not None:\n        _check_row_count(\"node\")\n\n    if hasattr(koza_app, \"edge_file\") and source_config.min_edge_count is not None:\n        _check_row_count(\"edge\")\n</code></pre>"},{"location":"Usage/Module/#src.koza.cli_utils.validate_file","title":"<code>validate_file</code>","text":"<p>Runs a file through one of the Koza readers For csv files will return header and row length</p> <p>For json and jsonl just validates them</p> Source code in <code>src/koza/cli_utils.py</code> <pre><code>def validate_file(\n    file: str,\n    format: FormatType = FormatType.csv,\n    delimiter: str = \",\",\n    header_delimiter: str = None,\n    skip_blank_lines: bool = True,\n):\n    \"\"\"\n    Runs a file through one of the Koza readers\n    For csv files will return header and row length\n\n    For json and jsonl just validates them\n    \"\"\"\n\n    with open_resource(file) as resource_io:\n        if format == FormatType.csv:\n            reader = CSVReader(\n                resource_io,\n                delimiter=delimiter,\n                header_delimiter=header_delimiter,\n                skip_blank_lines=skip_blank_lines,\n            )\n        elif format == FormatType.jsonl:\n            reader = JSONLReader(resource_io)\n        elif format == FormatType.json:\n            reader = JSONReader(resource_io)\n        else:\n            raise ValueError\n\n        for _ in reader:\n            pass\n</code></pre>"}]}